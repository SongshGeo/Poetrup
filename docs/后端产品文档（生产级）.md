---
cate: 方法
date: 2025-11-16
tags:
  - output
banner: "40 - Obsidian/img/方法.jpg"
longform: false
---
# 后端产品文档（生产级）

**目标用户群：中文为主的词语采集 + 拼贴诗创作 APP（Web + iOS）**  
本文档覆盖数据库 schema 摘要、中文分词实现方案、RLS（行级安全）策略 SQL、REST API（详细端点、请求/响应示例）、后台任务/管道、存储策略、备份与运维、扩容与迁移策略、监控与预警、以及部署/CI/CD 建议。你可以直接用于 Supabase（托管或 self-hosted）+ Edge Functions + 后台 worker 的生产环境准备。

---

# 1 概览与架构图（文字版）

- 前端：Next.js (Web) / SwiftUI (iOS)
    
- 认证：Supabase Auth (OAuth: Google/GitHub + Email)
    
- 数据库：Postgres（Supabase 托管）
    
- 存储：Supabase Storage（buckets：avatars, collection-covers, user-uploads, exports）
    
- 实时/同步：Supabase Realtime（DB change feed）
    
- 后台服务：Edge Functions（轻量任务） + Worker（长时任务，如 embedding、thumbnail）
    
- 搜索：Postgres `tsvector`（结合中文分词） + pg_trgm；语义搜索使用 pgvector（或单独向量库）
    
- 日志/审计：activity_logs 表 + 外部 log aggregator（例如 Datadog / Prometheus + Loki/Elasticsearch）
    
- 备份：每日 pg_dump 到对象存储并异地保存
    

---

# 2 数据库（简要重述与关键点）

（已实现的主表：profiles、words、collections、collection_words、collection_collaborators、poetry、poetry_collections、favorites、media、activity_logs）

要点：

- `words` 包含 `text`、`normalized`、`language`、`metadata(jsonb)`、`tsv`（全文搜索），可选 `vector`（pgvector）列用于 embedding。
    
- `collections` 支持 `visibility`（private/shared/public）与 `metadata` 存放 UI 布局/主题。
    
- `poetry.content` 用 JSONB 存储 block/position/word_id，以便前端还原。
    
- `media` 仅存元数据，对象存储保存实际文件。
    
- 所有表包含 `created_at`/`updated_at`/`deleted_at`（软删除）。
    

---

# 3 中文分词（生产级实现方案）

中文搜索 / 精确检索与模糊检索关键在于**分词**。在 Postgres 端直接对中文做理想的分词并不完美（Postgres 默认 tsvector 不适合中文），因此我们采用 **应用层分词 + 将分词结果写入数据库的混合方案**。

## 3.1 方案总览（推荐）

1. **客户端/Edge Function 需要做两件事：**
    
    - 当用户创建/上传 `word` 或 `poetry.content` 时，发送到后端的请求同时包含一个 `tokens` 字段（由后端或 Edge Function 根据原文分词生成）。
        
    - 后端把 `tokens` 写入 `words.normalized`、`words.tsv` 与 `words.tokens`（可作为 JSONB）或单独建立 `word_tokens` 表索引。
        
2. **分词工具（应用层）**
    
    - 推荐：**jieba**（Python）或 **HanLP / jieba3k / pkuseg**（可选更高质量）。
        
    - 在 Edge Function 或后端的 worker 中运行分词：对单词、诗歌文本做分词、去停用词、去标点、规范化（小写、去音标）。
        
3. **写入数据库：**
    
    - 写入 `words.normalized` = tokens 连接字符串（空格分隔），以便 `to_tsvector('simple', normalized)` 工作。
        
    - 同时写入 `words.tokens`（jsonb array）保存原始分词，便于推荐与统计。
        
    - 若启用 pgvector：对 `words.text` 或 `tokens` 调用 embedding 服务（例如 OpenAI embedding 或本地模型），把向量写入 `words.vector`。
        
4. **搜索实现：**
    
    - 对于中文模糊匹配：使用 `gin (tsv)` + `gin_trgm_ops` on original text（针对字/短语的 trigram 可提高容错）。
        
    - 搜索入口会先做分词然后构造 tsquery（例如把用户搜索“秋天 草地”分词成 `秋天 & 草地`），再查询 `tsv @@ to_tsquery(...)`。
        
    - 对语义搜索使用向量相似度（pgvector `vector <=> query_vector`）。
        

## 3.2 详细示例（Python Edge Function）

下面伪代码示例展示如何在 Edge Function 中做分词并写数据库（使用 Python + jieba）：

```python
# 伪代码：Edge Function / Worker
import jieba
import requests
import json

def tokenize_chinese(text: str):
    words = [w for w in jieba.cut_for_search(text) if w.strip()]
    # 去停用词、去标点（可用停用词表）
    return words

def handle_create_word(payload):
    text = payload['text']
    tokens = tokenize_chinese(text)
    normalized = ' '.join(tokens)
    # optional: compute embedding via external API to get vector
    # send to backend (Supabase REST / Edge Function) to create row
    body = {
      "text": text,
      "normalized": normalized,
      "tokens": tokens,
      "language": "zh",
      "source": payload.get("source","user_input")
    }
    resp = requests.post("https://api.example.com/words", json=body, headers={"Authorization": "Bearer ..."})
```

## 3.3 数据库侧支持（触发器/字段）

- `words` 增加 `tokens jsonb` 字段（保存词数组），`normalized` 与 `tsv` 由插入/更新时触发器自动保持一致（如果前端直接传 normalized，则触发器以传入为准或再次 normalize）。
    
- 对 `poetry.content`：Edge Function 在将 `content` 写入 DB 前，抽取所有文本片段做分词/拼接写入 `poetry.text_content`。
    

## 3.4 处理长文本与中文分词注意点

- 中文搜索的分词质量决定检索效果：建议维护停用词表、同义词表（“海洋” ↔ “大海”），并在推荐系统中应用同义扩展。
    
- 如果需要更专业中文分词（词性、命名实体、依存关系），考虑引入 HanLP / THULAC / pkuseg 等更强工具，但它们需要更多资源。
    

---

# 4 RLS（行级安全）策略（Supabase 可直接使用的 SQL）

下面给出一套生产级的 RLS 策略 SQL 模板（在 Supabase SQL Editor 里执行）。**注意**：需先启用 RLS 开关 `ALTER TABLE ... ENABLE ROW LEVEL SECURITY;` 并确保 `auth.uid()` 可用（Supabase 环境）。

> **警告**：在复制到你的项目之前，先在 dev 环境充分测试这些 policy，避免意外锁住数据访问。

```sql
-- profiles：只有用户自己或管理员可读写（假设 admin role 在 auth.claims 中有 is_admin）
ALTER TABLE profiles ENABLE ROW LEVEL SECURITY;

CREATE POLICY "profiles_select_own_or_admin" ON profiles
  FOR SELECT USING (
    auth.uid() IS NOT NULL AND (auth.uid() = auth_uid OR current_setting('jwt.claims.is_admin', true) = 'true')
  );

CREATE POLICY "profiles_update_own" ON profiles
  FOR UPDATE USING (
    auth.uid() = auth_uid
  ) WITH CHECK (
    auth.uid() = auth_uid
  );

-- collections: read if public OR owner OR collaborator OR admin
ALTER TABLE collections ENABLE ROW LEVEL SECURITY;

CREATE POLICY "collections_select_public_owner_collab_admin" ON collections
  FOR SELECT USING (
    visibility = 'public'
    OR owner_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
    OR EXISTS (
      SELECT 1 FROM collection_collaborators cc
      JOIN profiles p ON p.id = cc.profile_id
      WHERE cc.collection_id = collections.id AND p.auth_uid = auth.uid()
    )
    OR current_setting('jwt.claims.is_admin', true) = 'true'
  );

-- insert: allow any authenticated user to create, owner_id must map to auth.uid()
CREATE POLICY "collections_insert_auth" ON collections
  FOR INSERT WITH CHECK (
    owner_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
  );

-- update/delete: only owner or admin or collaborator with editor role
CREATE POLICY "collections_modify_owner_or_editor" ON collections
  FOR UPDATE, DELETE USING (
    owner_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
    OR EXISTS (
      SELECT 1 FROM collection_collaborators cc
      JOIN profiles p ON p.id = cc.profile_id
      WHERE cc.collection_id = collections.id
        AND p.auth_uid = auth.uid()
        AND cc.role IN ('owner','editor')
    )
    OR current_setting('jwt.claims.is_admin', true) = 'true'
  );

-- collection_words: insert if you are owner/editor/collaborator
ALTER TABLE collection_words ENABLE ROW LEVEL SECURITY;
CREATE POLICY "cw_insert_collab_owner" ON collection_words
  FOR INSERT WITH CHECK (
    EXISTS (
      SELECT 1 FROM collections c
      WHERE c.id = collection_words.collection_id
        AND (
          c.owner_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
          OR EXISTS (
            SELECT 1 FROM collection_collaborators cc
            JOIN profiles p ON p.id = cc.profile_id
            WHERE cc.collection_id = c.id
              AND p.auth_uid = auth.uid()
              AND cc.role IN ('owner','editor')
          )
        )
    )
  );

-- words: insert by any authenticated user, update/delete only creator or admin
ALTER TABLE words ENABLE ROW LEVEL SECURITY;
CREATE POLICY "words_insert_auth" ON words
  FOR INSERT WITH CHECK (
    creator_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
  );

CREATE POLICY "words_update_delete_creator_or_admin" ON words
  FOR UPDATE, DELETE USING (
    creator_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
    OR current_setting('jwt.claims.is_admin', true) = 'true'
  );

-- poetry: public read OR owner OR collaborators (if you allow collaboration)
ALTER TABLE poetry ENABLE ROW LEVEL SECURITY;
CREATE POLICY "poetry_select_public_owner_admin" ON poetry
  FOR SELECT USING (
    -- you can define poetry.metadata->>'visibility' OR link to collection visibility
    (poetry.metadata->>'visibility') = 'public'
    OR creator_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
    OR current_setting('jwt.claims.is_admin', true) = 'true'
  );

CREATE POLICY "poetry_insert_auth" ON poetry
  FOR INSERT WITH CHECK (
    creator_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
  );

CREATE POLICY "poetry_update_delete_owner_admin" ON poetry
  FOR UPDATE, DELETE USING (
    creator_id = (SELECT id FROM profiles WHERE auth_uid = auth.uid())
    OR current_setting('jwt.claims.is_admin', true) = 'true'
  );
```

> 说明：`current_setting('jwt.claims.is_admin', true)` 假设你在 JWT claims 加入 `is_admin`。Supabase 控制台也允许你基于 `auth.role` 设置策略。测试每条 policy 的读写行为以免锁表。

---

# 5 REST API（生产级设计，分页、过滤、安全与示例）

下面列出关键端点（包含认证、分页与排序约定、错误响应格式、速率建议）。建议在 API 网关（Edge Functions 或后端服务）层面控制复杂事务或聚合查询，简单 CRUD 可直接使用 Supabase 自动 REST（若你用 Supabase 自动生成 REST，注意 RLS 会自动生效）。

## 5.1 公共约定

- 认证：Bearer JWT（来自 Supabase Auth）
    
- 所有 `GET` 支持常见分页参数：`?page=1&per_page=20`（默认 `per_page=20`, 最大 `per_page=100`）
    
- 排序：`?sort=created_at.desc` 或 `?sort=popularity.desc`
    
- 过滤：以查询参数为主，例如 `?tag=自然&language=zh`
    
- 错误响应（RFC7807 风格简化）：
    

```json
{
  "error": {
    "code": "invalid_request",
    "message": "Missing field 'text'",
    "details": { "field": "text" }
  }
}
```

## 5.2 关键端点（摘要）

> 这里只给出主要端点与示例请求/响应。完整 OpenAPI 可根据此扩展（可在后续生成）。

### Auth

- `POST /auth/signup`（外部由 Supabase Auth 提供）
    
- `POST /auth/login`（由 Supabase Auth 提供）
    
- `GET /auth/me` → 返回 `profiles` 信息
    

### Words（词语）

- `POST /api/v1/words`
    
    - Body:
        
        ```json
        {
          "text": "高山",
          "language": "zh",
          "tags": ["自然"],
          "source": "user_input",
          "tokens": ["高山"]
        }
        ```
        
    - Response: `201 Created` 返回 word 对象（包含 id）
        
- `GET /api/v1/words/{word_id}`
    
- `GET /api/v1/words?query=山&tag=自然&language=zh&page=1&per_page=20`
    
    - 搜索：后端会先对 query 做分词构造 tsquery
        
- `PATCH /api/v1/words/{word_id}`
    
- `DELETE /api/v1/words/{word_id}`
    

### Collections（词语收藏册）

- `POST /api/v1/collections`
    
    - Body:
        
        ```json
        { "title": "...", "description":"...", "visibility":"private", "tags":["旅行"] }
        ```
        
- `GET /api/v1/collections/{id}` → 返回 collection + words（分页）
    
- `PATCH /api/v1/collections/{id}`
    
- `DELETE /api/v1/collections/{id}`
    

#### 管理 collection 的词语

- `POST /api/v1/collections/{id}/words` `{ "word_id": "...", "position": 5 }`
    
- `DELETE /api/v1/collections/{id}/words/{word_id}`
    
- `GET /api/v1/collections/{id}/words?page=1&per_page=50`
    

#### 协作

- `POST /api/v1/collections/{id}/collaborators` `{ "profile_id":"...", "role":"editor" }`
    
- `GET /api/v1/collections/{id}/collaborators`
    
- `DELETE /api/v1/collections/{id}/collaborators/{profile_id}`
    

### Poetry（拼贴诗）

- `POST /api/v1/poetry`
    
    - Body:
        
        ```json
        {
          "title":"秋天的风",
          "description":"...",
          "collection_ids":["..."],
          "content":[
             {"type":"word", "word_id":"...", "text":"高山", "x":100, "y":200},
             {"type":"text", "text":"一段自定义文字", "x":50, "y":20}
          ],
          "metadata": {"visibility":"public"}
        }
        ```
        
    - 备注：后端会把 content 中的文本抽取并分词写入 `text_content` 与 `tsv`
        
- `GET /api/v1/poetry/{id}` → 展示完整 content（前端可渲染）
    
- `PATCH /api/v1/poetry/{id}`
    
- `DELETE /api/v1/poetry/{id}`
    
- `POST /api/v1/poetry/{id}/favorite`
    
- `DELETE /api/v1/poetry/{id}/favorite`
    

### Favorites / User endpoints

- `GET /api/v1/users/{id}/collections`
    
- `GET /api/v1/users/{id}/poetry`
    
- `GET /api/v1/me/favorites`
    

### Search / Explore

- `GET /api/v1/search?type=words&q=秋天 草地&page=1`
    
    - 后端先对 `q` 做分词，构建 tsquery，返回排名靠前的 words + snippets
        
- `GET /api/v1/explore/suggestions` → returns recommended words based on user's recent activity (Edge Function)
    

### Media Uploads

- `POST /api/v1/uploads` → 返回 presigned URL 或直接使用 Supabase Storage SDK。上传后写入 `media` 表。
    

---

# 6 后台任务与数据管道（生产级）

## 6.1 任务类型

- **Thumbnail generation**：上传图片后异步生成多尺寸（small/medium/large），保存到 `media` 表的 metadata。
    
- **Embedding / Semantic pipeline**：新创建 word 或 poetry 时，异步调用 embedding 服务（外部 API 或本地模型），写入 `words.vector` / `poetry_embeddings` 表。
    
- **Popularity / Trending**：批量 job 统计 `usage_count`、`favorite_count` 并生成 materialized view `trending_words` 每小时刷新。
    
- **Cleanup job**：定期 purge `deleted_at` 30 天前的数据（或按 GDPR 要求）。
    
- **Backup job**：每日导出 pg_dump 并复制到对象存储与异地。
    

## 6.2 实现建议

- 使用 Supabase Edge Functions / Cloud Run / AWS Lambda + Pub/Sub（如 Redis Streams / RabbitMQ / Cloud Tasks）来运行异步任务。
    
- Embedding pipeline：任务消费队列 -> 调用 embedding api -> 更新 DB -> 更新向量索引。
    
- Thumbnail/Image：上传 -> 触发 Storage webhook -> push job -> worker 处理 -> 更新 `media`。
    

---

# 7 存储桶与文件管理策略

- Buckets:
    
    - `avatars`（public，头像，自动生成多个尺寸）
        
    - `collection-covers`（public）
        
    - `user-uploads`（private，原图）
        
    - `exports`（private，导出后 TTL）
        
- 文件命名：`{bucket}/{profile_id}/{uuid}-{size}.jpg`
    
- CDN：对 public bucket 配置 CDN（或 Cloudflare），减少 egress 压力。
    
- 缩略图策略：上传后 worker 生成并写入 metadata，前端可以请求不同尺寸。
    

---

# 8 备份、恢复与迁移

- **备份策略**：
    
    - 每日全量备份（pg_dump），保留 30 天。
        
    - 增量日志（WAL）如果可用，配置连续归档（Point-in-time recovery）。
        
    - 对 media 做异地复制（例如把 Supabase Storage 对象复制到 AWS S3/Backblaze）。
        
- **恢复演练**：每季度一次恢复演练（从备份恢复到 dev 环境，验证数据一致性）。
    
- **迁移到 self-hosted**：
    
    1. 导出 pg_dump + 所有 media。
        
    2. 在自托管环境恢复 DB，配置 Supabase stack 或自建后端。
        
    3. 更新 DNS 与客户端配置，逐步切换流量（蓝绿/渐进迁移）。
        
    4. 需要注意 RLS / Auth claims 在自托管下的映射。
        

---

# 9 安全与合规

- HTTPS 强制（前端与所有 API）
    
- JWT token 生命周期短（refresh token 机制）
    
- 存储敏感数据加密（如果需要）
    
- GDPR：实现“用户数据导出 / 删除”接口，软删除 +最终物理删除（30 天队列），记录删除同意/请求
    
- 审计：关键操作写入 activity_logs，保留至少 90 天（或按合规要求）
    

---

# 10 监控与报警（关键指标与阈值建议）

监控数值（例）：

- DB size > 70% of quota → 报警
    
- Table bloat ratio > 20% on main tables → 报警
    
- Active DB connections > 80% of max_connections → 报警
    
- 5xx API rate > baseline*3 in 5 min → 报警
    
- Edge Function queue length > threshold → 报警
    
- Egress bandwidth daily > 80% of tier limit → 报警
    

建议工具：Prometheus + Grafana（指标），Sentry（错误监控），Datadog（综合监控）

---

# 11 性能与扩容策略

- **读扩展**：用缓存（Redis）缓存热门集合、热门词、用户 feed；对热点读请求使用 CDN。
    
- **写扩展**：分离长时任务为异步后台，减少同步阻塞。
    
- **搜索扩展**：当 tsvector + pg_trgm 不够时，考虑 Typesense / Elasticsearch / MeiliSearch 做全文与高质量中文分词查询（分词器可定制）。
    
- **向量搜索**：若语义搜索增长快速，迁移到专门的向量数据库（Milvus / Pinecone / Weaviate）会更高效。
    

---

# 12 开发 / 部署 / CI 流程建议

- GitFlow 分支策略（main/prod、develop/staging、feature/*）
    
- Terraform / Pulumi 管理 infra（buckets、DNS、cloud run）
    
- DB Migrations：使用 Flyway / Sqitch / Hasura Migrations / Supabase Migrations 管理 SQL DDL ，所有 schema 变更通过 PR + review + CI-run migrations
    
- CI：Pull Request → run lint/tests → run DB migration on ephemeral DB → deploy to staging → e2e tests → deploy to production
    
- DB schema changes：先做 backward-compatible 的迁移步骤（add columns → backfill → switch code → drop old columns）
    

---

# 13 日志、错误码与 API contracts（建议）

- 使用统一错误码体系（`ERR_` 前缀 + HTTP code 映射），并在 OpenAPI 中定义所有错误响应。
    
- 例如：
    
    - `ERR_AUTH_REQUIRED` (401)
        
    - `ERR_NOT_FOUND` (404)
        
    - `ERR_FORBIDDEN` (403)
        
    - `ERR_VALIDATION` (422)
        
    - `ERR_RATE_LIMIT` (429)
        
- 对于长任务，返回 `202 Accepted` 并提供 `Location` 指向 `GET /tasks/{task_id}` 查询状态。
    

---

# 14 迁移与演进路线（短期 / 中期 / 长期）

- **短期（MVP）**：Supabase Free/Pro，Edge Functions 处理分词与 thumbnails；jieba 做分词；基础 RLS；每日备份。
    
- **中期（增长）**：付费 Supabase plan（更大 DB）或自建 Postgres；启用 pgvector 并建立 embedding pipeline；加入 Redis 缓存与 CDN。
    
- **长期（大规模）**：切换全文/搜索到专门服务（Typesense/ES），向量搜索外包/迁移到专用服务，完全自托管 Supabase stack 或分离 DB 与服务以实现更灵活扩展。
    

---

# 15 下一步我可以直接交付的可执行产物（你选其一或多项，我立刻生成）

1. **完整 OpenAPI 3.0 文档（包含所有端点、请求/响应示例、错误码）**。
    
2. **Supabase-ready SQL（含表、索引、触发器 + 完整 RLS SQL）**，可直接在 Supabase SQL 编辑器执行（我会把 `ALTER TABLE ... ENABLE ROW LEVEL SECURITY` 与 policy 列出并解释）。
    
3. **Edge Function（Python）示例**：包含 jieba 分词、调用 embedding 的可运行代码样板、并展示如何将 tokens/normalized 写入 DB。
    
4. **CI/CD + Migration 示例**（Terraform + GitHub Actions + Flyway 脚本）。
    
5. **容量估算 & 成本估算表格**（给出不同增长场景下 DB/Storage/egress 需求与付费建议）。
    

告诉我你想要哪一项（或全部），我就把对应交付物立刻生成并给出下载/复制内容。